{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dca17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes: 180283\n",
      "Total Edges: 286561\n"
     ]
    }
   ],
   "source": [
    "import snap\n",
    "import re\n",
    "\n",
    "# ENCRYPT COZ POST ID CAN ONLY BE INT\n",
    "\n",
    "def convert_to_integer(post_id):\n",
    "    base = 36  # 10 digits + 26 letters\n",
    "\n",
    "    # Remove leading and trailing single quotes if present\n",
    "    post_id = post_id.strip(\"'\")\n",
    "\n",
    "    # Convert each character to its corresponding integer value\n",
    "    int_values = [int(c, base) for c in post_id]\n",
    "\n",
    "    # Combine the integer values to get a unique integer for the whole string\n",
    "    result = 0\n",
    "    for value in int_values:\n",
    "        result = result * base + value\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Create a bipartite graph\n",
    "G = snap.TNEANet.New()\n",
    "\n",
    "# Load post crosslinks info\n",
    "with open('formatted_data_file.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Split the data into lines\n",
    "lines = data.strip().split('\\n')\n",
    "\n",
    "# Mapping between community and user names and their node IDs\n",
    "community_to_id = {}\n",
    "user_to_id = {}\n",
    "\n",
    "# Add nodes and edges to the bipartite graph\n",
    "for line in lines:\n",
    "    parts = re.split(r'\\t|\\s', line)\n",
    "\n",
    "    # Extract values into variables\n",
    "    source_community = parts[0]\n",
    "    target_community = parts[1]\n",
    "    post_id_source = parts[2]\n",
    "    timestamp_source = parts[3] + \" \" + parts[4]  # Combine date and time\n",
    "    user = parts[5]\n",
    "    post_id_target = parts[6]\n",
    "    timestamp_target = parts[7] + \" \" + parts[8]  # Combine date and time\n",
    "    \n",
    "    # Add nodes if they don't exist\n",
    "    if source_community not in community_to_id:\n",
    "        source_community_id = G.AddNode()\n",
    "        community_to_id[source_community] = source_community_id\n",
    "    else:\n",
    "        source_community_id = community_to_id[source_community]\n",
    "\n",
    "    if user not in user_to_id:\n",
    "        user_id = G.AddNode()\n",
    "        user_to_id[user] = user_id\n",
    "    else:\n",
    "        user_id = user_to_id[user]\n",
    "\n",
    "    if target_community not in community_to_id:\n",
    "        target_community_id = G.AddNode()\n",
    "        community_to_id[target_community] = target_community_id\n",
    "    else:\n",
    "        target_community_id = community_to_id[target_community]\n",
    "\n",
    "    # Add edges\n",
    "    # G.AddEdge(source_community_id, user_id)\n",
    "    G.AddEdge(user_id, target_community_id)\n",
    "\n",
    "# Load label info\n",
    "with open('label_info.tsv', 'r') as file:\n",
    "    label_info = file.read()\n",
    "\n",
    "# Split label info into lines\n",
    "label_lines = label_info.strip().split('\\n')\n",
    "\n",
    "# Add sentiment attribute to edges\n",
    "for label_line in label_lines:\n",
    "    parts = label_line.split()\n",
    "    if len(parts) != 3:\n",
    "        print(f\"Skipping label line: {label_line}\")\n",
    "        continue\n",
    "\n",
    "    post_id_from, post_id_to, sentiment = parts[0][1:-1], parts[1][:-1], parts[2]\n",
    "    # Convert alphanumeric post IDs to integers\n",
    "    post_id_from_int = convert_to_integer(post_id_from)\n",
    "    post_id_to_int = convert_to_integer(post_id_to)\n",
    "     \n",
    "    # Find edge IDs based on source and target node IDs\n",
    "    edge_id = G.GetEId(user_id, target_community_id)\n",
    "\n",
    "    # Map sentiment values to 1 and 0\n",
    "    sentiment_value = 1 if sentiment == 'burst' else 0 \n",
    "\n",
    "    # Add sentiment attribute to edges\n",
    "    G.AddIntAttrDatE(edge_id, sentiment_value, \"sentiment\")\n",
    "\n",
    "# Print the total number of nodes and edges\n",
    "print(\"Total Nodes:\", G.GetNodes())\n",
    "print(\"Total Edges:\", G.GetEdges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216a6865",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: \"('2vjbm2',\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m label_lines \u001b[38;5;241m=\u001b[39m label_info\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Labeling nodes based on sentiment\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m labels \u001b[38;5;241m=\u001b[39m [G\u001b[38;5;241m.\u001b[39mGetIntAttrDatE(\u001b[38;5;28mint\u001b[39m(parts[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m parts \u001b[38;5;129;01min\u001b[39;00m (line\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m label_lines)]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n\u001b[0;32m     47\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(features, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     41\u001b[0m label_lines \u001b[38;5;241m=\u001b[39m label_info\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Labeling nodes based on sentiment\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m labels \u001b[38;5;241m=\u001b[39m [G\u001b[38;5;241m.\u001b[39mGetIntAttrDatE(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m parts \u001b[38;5;129;01min\u001b[39;00m (line\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m label_lines)]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n\u001b[0;32m     47\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(features, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: \"('2vjbm2',\""
     ]
    }
   ],
   "source": [
    "import snap\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Your existing code for creating the bipartite graph (up to the sentiment attribute)\n",
    "\n",
    "# Feature extraction\n",
    "user_out_degree = {}\n",
    "user_in_degree = {}\n",
    "user_negative_sentiments = {}\n",
    "\n",
    "for user_id in user_to_id.values():\n",
    "    # Out-degree of the user node\n",
    "    out_degree = G.GetNI(user_id).GetOutDeg()\n",
    "    user_out_degree[user_id] = out_degree\n",
    "\n",
    "    # In-degree of the user node\n",
    "    in_degree = G.GetNI(user_id).GetInDeg()\n",
    "    user_in_degree[user_id] = in_degree\n",
    "\n",
    "    # Sentiment of neighboring edges\n",
    "    neighboring_sentiments = [G.GetIntAttrDatE(eid, \"sentiment\") for eid in G.GetNI(user_id).GetOutEdges()]\n",
    "    user_negative_sentiments[user_id] = sum(1 for sentiment in neighboring_sentiments if sentiment == 1)\n",
    "\n",
    "# Convert features to a numpy array\n",
    "features = np.array([\n",
    "    list(user_out_degree.values()),\n",
    "    list(user_in_degree.values()),\n",
    "    list(user_negative_sentiments.values())\n",
    "]).T\n",
    "\n",
    "# Load label info\n",
    "with open('label_info.tsv', 'r') as file:\n",
    "    label_info = file.read()\n",
    "\n",
    "# Split label info into lines\n",
    "label_lines = label_info.strip().split('\\n')\n",
    "\n",
    "# Labeling nodes based on sentiment\n",
    "labels = [G.GetIntAttrDatE(int(parts[0]), \"sentiment\") for parts in (line.split() for line in label_lines)]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Plotting the graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(user_out_degree.values(), user_negative_sentiments.values(), alpha=0.5)\n",
    "plt.title('User Out-Degree vs. Number of Negative Sentiments (Neighboring Edges)')\n",
    "plt.xlabel('User Out-Degree')\n",
    "plt.ylabel('Number of Negative Sentiments (Neighboring Edges)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a91b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
